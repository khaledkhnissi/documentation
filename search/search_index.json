{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"competition-overview/","text":"Competition Overview Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase. Simulation Phase In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams will follow the instructions in this documentation to set up their PCs and download the complete simulation packages required to complete the tasks. Teams are required to complete and upload their solutions on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2. Physical Robot Phase In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review. Competition Prizes The 1st place winner: $2,000 Other awards for top teams include prizes from sponsors such as laptops, tablets mentoring! How to Register Prospective teams are required to complete an online application . Team Profile After you register, your team must complete the Team profile form . Important Dates Event Date Registration Opens February 20th 2021 Registration Deadline March 20th 2021 Phase 1 Submission Deadline May 16th 2021 Phase 2 Qualification Announcement May 28th 2021 Phase 2 Kick-Off July 16th 2021 Phase 2 Testing Period July 29th-August 25th 2021 Phase 2 Submission Deadline August 25th 2021 Final Competition Days August 27th-28th 2021","title":"Competition Overview"},{"location":"competition-overview/#competition_overview","text":"Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase.","title":"Competition Overview"},{"location":"competition-overview/#simulation_phase","text":"In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams will follow the instructions in this documentation to set up their PCs and download the complete simulation packages required to complete the tasks. Teams are required to complete and upload their solutions on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2.","title":"Simulation Phase"},{"location":"competition-overview/#physical_robot_phase","text":"In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review.","title":"Physical Robot Phase"},{"location":"competition-overview/#competition_prizes","text":"The 1st place winner: $2,000 Other awards for top teams include prizes from sponsors such as laptops, tablets mentoring!","title":"Competition Prizes"},{"location":"competition-overview/#how_to_register","text":"Prospective teams are required to complete an online application .","title":"How to Register"},{"location":"competition-overview/#team_profile","text":"After you register, your team must complete the Team profile form .","title":"Team Profile"},{"location":"competition-overview/#important_dates","text":"Event Date Registration Opens February 20th 2021 Registration Deadline March 20th 2021 Phase 1 Submission Deadline May 16th 2021 Phase 2 Qualification Announcement May 28th 2021 Phase 2 Kick-Off July 16th 2021 Phase 2 Testing Period July 29th-August 25th 2021 Phase 2 Submission Deadline August 25th 2021 Final Competition Days August 27th-28th 2021","title":"Important Dates"},{"location":"faqs/","text":"Frequently Asked Questions Who is eligible to compete? University Students Young Professionals, ages 18+. Teams must have 2-8 members. What specific skills does my team need to compete? Basic knowledge of Python or C++. What skills will my team enhance through participating in PARC? Developing robotic software in ROS Strengthen programming skills Real world robotics problem solving Implement computer vision solutions How does my team register to compete and when is the deadline? Visit www.parcrobotics.org to register to compete, the competition begins Feb 20, 2021 but the deadline to register is March 20, 2021. My team has registered, how do we get started? Teams receive the PARC 2021 Challenge and the \"Getting Started\" instructions to set up their computer and begin coding their solution. Do you have a question not addressed above, send your question to us here","title":"Frequently Asked Questions"},{"location":"faqs/#frequently_asked_questions","text":"Who is eligible to compete? University Students Young Professionals, ages 18+. Teams must have 2-8 members. What specific skills does my team need to compete? Basic knowledge of Python or C++. What skills will my team enhance through participating in PARC? Developing robotic software in ROS Strengthen programming skills Real world robotics problem solving Implement computer vision solutions How does my team register to compete and when is the deadline? Visit www.parcrobotics.org to register to compete, the competition begins Feb 20, 2021 but the deadline to register is March 20, 2021. My team has registered, how do we get started? Teams receive the PARC 2021 Challenge and the \"Getting Started\" instructions to set up their computer and begin coding their solution. Do you have a question not addressed above, send your question to us here","title":"Frequently Asked Questions"},{"location":"forum/","text":"Note Join the PARC2021 Engineers League Forum today. First, make a PARC account and then you can use the forum to ask questions and discuss topics related to PARC2021 Enigneers League. Click the image below to navigate to the forum site.","title":"Q & A Forum"},{"location":"getting-started/getting-started-with-ros/understanding-ros/","text":"Getting started with ROS The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms. We have planned this competition around ROS because of its features as well as its widespread use in robotics research and industry. To get started with ROS (if you are a beginner), we recommend you follow the \"Beginner Level\" tutorials in the official ROS Tutorials . Ensure you complete at least the following: Chapter 5 (ROS Nodes): \"This tutorial introduces ROS graph concepts and discusses the use of roscore, rosnode, and rosrun commandline tools\" Chapter 6 (ROS Topics): \"This tutorial introduces ROS topics as well as using the rostopic and rqt_plot commandline tools.\" Chapter 12 (Writing simple publisher and subscriber in Python) Understand the core tools provided by ROS , including RViz, rqt_graph, Gazebo, etc. After you complete the required tutorials listed above, you can start setting up the workspace . Assuming the workspace at ~/catkin_ws/ as completed from the steps done in setting up your workspace , This should be your folder structure till now. ~/catkin_ws/ \u251c\u2500\u2500 build/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u251c\u2500\u2500 devel/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 src/ \u251c\u2500\u2500 CMakeLists.txt \u2514\u2500\u2500 parc-engineers-league/ \u251c\u2500\u2500 parc-robot/ \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u2514\u2500\u2500 . First step is to create your solution folder in ~/catkin_ws/src/ , we can call it parc_solutions for example. mkdir ~/catkin_ws/src/parc_solutions Go inside the folder, cd ~/catkin_ws/src/parc_solutions And here you can create a new ROS package called test_publisher (for example) by running the command below, catkin_create_pkg test_publisher roscpp rospy std_msgs geometry_msgs Moving the Robot Programmically Setting up your workspace guide has already shown how to control the robot with keyboard using teleoperation But this guide will help you to move the robot by publishing commands to /cmd_vel topic programmically using a Python script. To do this, create a file, robot_publisher.py inside scripts folder in your ROS package (for example test_publisher ) and make it executable. mkdir test_publisher/scripts touch test_publisher/scripts/robot_publisher.py chmod +x test_publisher/scripts/robot_publisher.py NOTE: You need to change the permission of the file to executable to be able to run (as done in the last command shown above). Now open the file and copy and paste the following code inside: #!/usr/bin/env python Script to move Robot import rospy from geometry_msgs.msg import Twist import time def move_robot(): rospy.init_node('robot_publisher', anonymous=True) # Create a publisher which can talk to Robot and tell it to move pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10) # Set publish rate at 10 Hz rate = rospy.Rate(10) # Create a Twist message and add linear x and angular z values move_cmd = Twist() ######## Move Straight ######## print( Moving Straight ) move_cmd.linear.x = 0.5 # move in X axis at 0.5 m/s move_cmd.angular.z = 0.0 now = time.time() # For the next 4 seconds publish cmd_vel move commands while time.time() - now 4: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Rotating Counterclockwise ######## print( Rotating ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.3 # rotate at 0.3 rad/sec now = time.time() # For the next 3 seconds publish cmd_vel move commands while time.time() - now 3: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Stop ######## print( Stopping ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.0 # Giving both zero will stop the robot now = time.time() # For the next 1 seconds publish cmd_vel move commands while time.time() - now 1: pub.publish(move_cmd) # publish to Robot rate.sleep() print( Exit ) if __name__ == '__main__': try: move_robot() except rospy.ROSInterruptException: pass This code will make the robot move straight for 4 seconds, rotate counterclockwise for 3 seconds and then stop. To see it working, first run the robot in simulation by running the following command in one terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot task1.launch And run the following command in another terminal to run this new program: source ~/catkin_ws/devel/setup.bash rosrun test_publisher robot_publisher.py If you have set up everything well, you should see the robot moving in Gazebo as below:","title":"Getting started with ROS"},{"location":"getting-started/getting-started-with-ros/understanding-ros/#getting_started_with_ros","text":"The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms. We have planned this competition around ROS because of its features as well as its widespread use in robotics research and industry. To get started with ROS (if you are a beginner), we recommend you follow the \"Beginner Level\" tutorials in the official ROS Tutorials . Ensure you complete at least the following: Chapter 5 (ROS Nodes): \"This tutorial introduces ROS graph concepts and discusses the use of roscore, rosnode, and rosrun commandline tools\" Chapter 6 (ROS Topics): \"This tutorial introduces ROS topics as well as using the rostopic and rqt_plot commandline tools.\" Chapter 12 (Writing simple publisher and subscriber in Python) Understand the core tools provided by ROS , including RViz, rqt_graph, Gazebo, etc. After you complete the required tutorials listed above, you can start setting up the workspace . Assuming the workspace at ~/catkin_ws/ as completed from the steps done in setting up your workspace , This should be your folder structure till now. ~/catkin_ws/ \u251c\u2500\u2500 build/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u251c\u2500\u2500 devel/ \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 src/ \u251c\u2500\u2500 CMakeLists.txt \u2514\u2500\u2500 parc-engineers-league/ \u251c\u2500\u2500 parc-robot/ \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u2514\u2500\u2500 . First step is to create your solution folder in ~/catkin_ws/src/ , we can call it parc_solutions for example. mkdir ~/catkin_ws/src/parc_solutions Go inside the folder, cd ~/catkin_ws/src/parc_solutions And here you can create a new ROS package called test_publisher (for example) by running the command below, catkin_create_pkg test_publisher roscpp rospy std_msgs geometry_msgs","title":"Getting started with ROS"},{"location":"getting-started/getting-started-with-ros/understanding-ros/#moving_the_robot_programmically","text":"Setting up your workspace guide has already shown how to control the robot with keyboard using teleoperation But this guide will help you to move the robot by publishing commands to /cmd_vel topic programmically using a Python script. To do this, create a file, robot_publisher.py inside scripts folder in your ROS package (for example test_publisher ) and make it executable. mkdir test_publisher/scripts touch test_publisher/scripts/robot_publisher.py chmod +x test_publisher/scripts/robot_publisher.py NOTE: You need to change the permission of the file to executable to be able to run (as done in the last command shown above). Now open the file and copy and paste the following code inside: #!/usr/bin/env python Script to move Robot import rospy from geometry_msgs.msg import Twist import time def move_robot(): rospy.init_node('robot_publisher', anonymous=True) # Create a publisher which can talk to Robot and tell it to move pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10) # Set publish rate at 10 Hz rate = rospy.Rate(10) # Create a Twist message and add linear x and angular z values move_cmd = Twist() ######## Move Straight ######## print( Moving Straight ) move_cmd.linear.x = 0.5 # move in X axis at 0.5 m/s move_cmd.angular.z = 0.0 now = time.time() # For the next 4 seconds publish cmd_vel move commands while time.time() - now 4: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Rotating Counterclockwise ######## print( Rotating ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.3 # rotate at 0.3 rad/sec now = time.time() # For the next 3 seconds publish cmd_vel move commands while time.time() - now 3: pub.publish(move_cmd) # publish to Robot rate.sleep() ######## Stop ######## print( Stopping ) move_cmd.linear.x = 0.0 move_cmd.angular.z = 0.0 # Giving both zero will stop the robot now = time.time() # For the next 1 seconds publish cmd_vel move commands while time.time() - now 1: pub.publish(move_cmd) # publish to Robot rate.sleep() print( Exit ) if __name__ == '__main__': try: move_robot() except rospy.ROSInterruptException: pass This code will make the robot move straight for 4 seconds, rotate counterclockwise for 3 seconds and then stop. To see it working, first run the robot in simulation by running the following command in one terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot task1.launch And run the following command in another terminal to run this new program: source ~/catkin_ws/devel/setup.bash rosrun test_publisher robot_publisher.py If you have set up everything well, you should see the robot moving in Gazebo as below:","title":"Moving the Robot Programmically"},{"location":"getting-started/setting-up-your-pc/","text":"How to setup the Computer This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of). System requirements The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed. Operating System If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency. Installing ROS You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Setting up your PC"},{"location":"getting-started/setting-up-your-pc/#how_to_setup_the_computer","text":"This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of).","title":"How to setup the Computer"},{"location":"getting-started/setting-up-your-pc/#system_requirements","text":"The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed.","title":"System requirements"},{"location":"getting-started/setting-up-your-pc/#operating_system","text":"If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency.","title":"Operating System"},{"location":"getting-started/setting-up-your-pc/#installing_ros","text":"You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Installing ROS"},{"location":"getting-started/setting-up-your-workspace/","text":"How to set up your workspace In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial) Setup ROS workspace Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace Clone the repository In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them. Install dependencies In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y Compile packages cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0 Set up ROS environment To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash Test installation If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot task1.launch Gazebo Simulator window RViz window If you run the following command in a new terminal, rqt_graph You will see a screen like this: You need to publish /write to the topic /cmd_vel to move the robot. The following guide will help you control the robot using keyboard. Once you have tested that, you can follow the understanding-ros guide to write a python program to control the robot. Controlling the robot using keyboard Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Setting up your Workspace"},{"location":"getting-started/setting-up-your-workspace/#how_to_set_up_your_workspace","text":"In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial)","title":"How to set up your workspace"},{"location":"getting-started/setting-up-your-workspace/#setup_ros_workspace","text":"Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace","title":"Setup ROS workspace"},{"location":"getting-started/setting-up-your-workspace/#clone_the_repository","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them.","title":"Clone the repository"},{"location":"getting-started/setting-up-your-workspace/#install_dependencies","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y","title":"Install dependencies"},{"location":"getting-started/setting-up-your-workspace/#compile_packages","text":"cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0","title":"Compile packages"},{"location":"getting-started/setting-up-your-workspace/#set_up_ros_environment","text":"To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash","title":"Set up ROS environment"},{"location":"getting-started/setting-up-your-workspace/#test_installation","text":"If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot task1.launch Gazebo Simulator window RViz window If you run the following command in a new terminal, rqt_graph You will see a screen like this: You need to publish /write to the topic /cmd_vel to move the robot. The following guide will help you control the robot using keyboard. Once you have tested that, you can follow the understanding-ros guide to write a python program to control the robot.","title":"Test installation"},{"location":"getting-started/setting-up-your-workspace/#controlling_the_robot_using_keyboard","text":"Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch parc-robot teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Controlling the robot using keyboard"},{"location":"phase1-instructions/","text":"Phase 1: Simulation In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores. Teams are provided with the delivery robot ROS packages and Gazebo environment models (see description below) to enable them develop and test their solutions (see GitHub Repository ). Delivery Robot The delivery robot is an unmanned ground vehicle (UGV) fitted with 2D LiDAR (light detection and ranging or laser scanner) and an RGB-Depth camera. The figure below shows the delivey robot with sensors labelled. Simulation Environment The simulation environment used in this phase is modeled as a realistic street with roads, sidewalk, crosswalk, traffic signals and buildings. The sidewalk is fitted with lane markings to ease the task of sidewalk following. The goal of the competition is to pick up a parcel from the store (side of the building) and deliver it to the person in the park. The figure below shows the simulation environment with labels of significant objects.","title":"Introduction"},{"location":"phase1-instructions/#phase_1_simulation","text":"In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores. Teams are provided with the delivery robot ROS packages and Gazebo environment models (see description below) to enable them develop and test their solutions (see GitHub Repository ).","title":"Phase 1: Simulation"},{"location":"phase1-instructions/#delivery_robot","text":"The delivery robot is an unmanned ground vehicle (UGV) fitted with 2D LiDAR (light detection and ranging or laser scanner) and an RGB-Depth camera. The figure below shows the delivey robot with sensors labelled.","title":"Delivery Robot"},{"location":"phase1-instructions/#simulation_environment","text":"The simulation environment used in this phase is modeled as a realistic street with roads, sidewalk, crosswalk, traffic signals and buildings. The sidewalk is fitted with lane markings to ease the task of sidewalk following. The goal of the competition is to pick up a parcel from the store (side of the building) and deliver it to the person in the park. The figure below shows the simulation environment with labels of significant objects.","title":"Simulation Environment"},{"location":"phase1-instructions/how-to-submit/","text":"How to Submit Teams are expected to develop their solutions (ROS packages) in a 'solutions' folder inside the ~/catkin_ws/src directory. You may have one or more ROS packages in this folder for all your tasks. See figure below of expected directory structure: ~/catkin_ws/src \u251c\u2500\u2500 CMakeLists.txt \u251c\u2500\u2500 parc-engineers-league \u2502 \u251c\u2500\u2500 parc-robot \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2502 \u2514\u2500\u2500 package.xml \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 YOUR_SOLUTION_FOLDER # Zip this folder and submit \u251c\u2500\u2500 your_ros_package1 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 your_ros_package2 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u2514\u2500\u2500 README.md # Required Prepare a README.md file following this format and store in solution folder (see example ): Introduction Section: Briefly describe your approach Dependencies: List all the packages installed and used in your solution Task 1 - 3 description and run command(s) Challenges faced Include all the packages (dependencies) used in your solution in your package's \"package.xml\" file ( see guide ) Zip your solution folder and upload on the solution submission form","title":"How to Submit"},{"location":"phase1-instructions/how-to-submit/#how_to_submit","text":"Teams are expected to develop their solutions (ROS packages) in a 'solutions' folder inside the ~/catkin_ws/src directory. You may have one or more ROS packages in this folder for all your tasks. See figure below of expected directory structure: ~/catkin_ws/src \u251c\u2500\u2500 CMakeLists.txt \u251c\u2500\u2500 parc-engineers-league \u2502 \u251c\u2500\u2500 parc-robot \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 . \u2502 \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2502 \u2514\u2500\u2500 package.xml \u2502 \u251c\u2500\u2500 . \u2502 \u2514\u2500\u2500 . \u2514\u2500\u2500 YOUR_SOLUTION_FOLDER # Zip this folder and submit \u251c\u2500\u2500 your_ros_package1 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 your_ros_package2 \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 . \u2502 \u251c\u2500\u2500 CMakeLists.txt \u2502 \u2514\u2500\u2500 package.xml \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u251c\u2500\u2500 . \u2514\u2500\u2500 README.md # Required Prepare a README.md file following this format and store in solution folder (see example ): Introduction Section: Briefly describe your approach Dependencies: List all the packages installed and used in your solution Task 1 - 3 description and run command(s) Challenges faced Include all the packages (dependencies) used in your solution in your package's \"package.xml\" file ( see guide ) Zip your solution folder and upload on the solution submission form","title":"How to Submit"},{"location":"phase1-instructions/task1/","text":"Task 1: Sidewalk following Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location on the sidewalk. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details]. Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task1.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere which represents the goal location . 2. Explore Multiple Routes We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch parc-robot task1.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations. 3. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . Hence, your solution to Task 1 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task1.launch In another terminal: roslaunch your-package-name task1_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles (postbox, fire hydrant, etc.) would be randomized. Task Rules and Scoring The time-limit to complete this task is 5 minutes (300 secs) . The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Out-of-lane distance Total distance traveled with any part of the robot lying outside the lane ( Smaller is better ) 2 Final travel distance to goal Shortest travel distance from robot (measured from robot center) to the goal which is calculated at the time limit [5 minutes] ( Smaller is better ) 3 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task 1: Sidewalk following"},{"location":"phase1-instructions/task1/#task_1_sidewalk_following","text":"Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location on the sidewalk. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details].","title":"Task 1: Sidewalk following"},{"location":"phase1-instructions/task1/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task1/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task1.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere which represents the goal location .","title":"1. Launching the Task"},{"location":"phase1-instructions/task1/#2_explore_multiple_routes","text":"We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch parc-robot task1.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations.","title":"2. Explore Multiple Routes"},{"location":"phase1-instructions/task1/#3_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . Hence, your solution to Task 1 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task1.launch In another terminal: roslaunch your-package-name task1_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles (postbox, fire hydrant, etc.) would be randomized.","title":"3. Preparing your Solution"},{"location":"phase1-instructions/task1/#task_rules_and_scoring","text":"The time-limit to complete this task is 5 minutes (300 secs) . The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Out-of-lane distance Total distance traveled with any part of the robot lying outside the lane ( Smaller is better ) 2 Final travel distance to goal Shortest travel distance from robot (measured from robot center) to the goal which is calculated at the time limit [5 minutes] ( Smaller is better ) 3 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase1-instructions/task2/","text":"Task 2: Traffic sign detection and recognition Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO). Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task2.launch You should see the display below in Gazebo. The robot needs to cross the crosswalk and reach the orange-red sphere ( goal location ) on the other side. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete. 2. Explore Multiple Start Delays We have provided a simple way to set arbitrary values for the start_delay . This can be done by passing an argument as follows (e.g. we set it to 20 here): roslaunch parc-robot task2.launch start_delay:=20 While developing, we recommend you play around with different values for the start_delay to ensure your solution is robust. Also we recommend you consider setting a high start_delay value when running your solution to account for any code start delays when you launch your code. 3. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task2_solution.launch . Hence, your solution to Task 2 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task2.launch In another terminal: roslaunch your-package-name task2_solution.launch Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign would be allowed, you must use a vision-based approach ONLY. If the use of a hack is found out, you will receive a ZERO score for this task. Task Rules and Scoring The GO-time (time duration with signal on GREEN) is set to 15 secs . This means that you have ~15 secs to cross the road and reach the goal location. The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You are required to stop when you arrive at the goal location. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Reaction time Time between traffic sign state change to GREEN and when robot starts to move ( Smaller is better ) 2 Goal completion 1 if robot reached the goal location, 0 otherwise 3 Safe crossing 1 if robot is within the crosswalk ONLY when the signal is GREEN, 0 otherwise (i.e. 0 if robot is on crosswalk when signal is RED). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task 2: Traffic sign detection and recognition"},{"location":"phase1-instructions/task2/#task_2_traffic_sign_detection_and_recognition","text":"Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO).","title":"Task 2: Traffic sign detection and recognition"},{"location":"phase1-instructions/task2/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task2/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task2.launch You should see the display below in Gazebo. The robot needs to cross the crosswalk and reach the orange-red sphere ( goal location ) on the other side. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete.","title":"1. Launching the Task"},{"location":"phase1-instructions/task2/#2_explore_multiple_start_delays","text":"We have provided a simple way to set arbitrary values for the start_delay . This can be done by passing an argument as follows (e.g. we set it to 20 here): roslaunch parc-robot task2.launch start_delay:=20 While developing, we recommend you play around with different values for the start_delay to ensure your solution is robust. Also we recommend you consider setting a high start_delay value when running your solution to account for any code start delays when you launch your code.","title":"2. Explore Multiple Start Delays"},{"location":"phase1-instructions/task2/#3_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task2_solution.launch . Hence, your solution to Task 2 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task2.launch In another terminal: roslaunch your-package-name task2_solution.launch Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign would be allowed, you must use a vision-based approach ONLY. If the use of a hack is found out, you will receive a ZERO score for this task.","title":"3. Preparing your Solution"},{"location":"phase1-instructions/task2/#task_rules_and_scoring","text":"The GO-time (time duration with signal on GREEN) is set to 15 secs . This means that you have ~15 secs to cross the road and reach the goal location. The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You are required to stop when you arrive at the goal location. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Reaction time Time between traffic sign state change to GREEN and when robot starts to move ( Smaller is better ) 2 Goal completion 1 if robot reached the goal location, 0 otherwise 3 Safe crossing 1 if robot is within the crosswalk ONLY when the signal is GREEN, 0 otherwise (i.e. 0 if robot is on crosswalk when signal is RED). 4 Completion time Time from launching the solution to task completion ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase1-instructions/task3/","text":"Task 3: Go-to-goal navigation The final task of this phase is to navigate safely through a park to reach the customer. The problem here is to navigate in an unconstrained but cluttered terrain without colliding with any obstacles. In this task you are required to move through a collision-free path to the goal using only your on-board sensors. Task 3 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location in the park without colliding with obstacles. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details]. Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. 1. Launching the Task In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task3.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere (the goal location ) in front of the person. 2. Preparing your Solution Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task3_solution.launch . Hence, your solution to Task 3 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task3.launch In another terminal: roslaunch your-package-name task3_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the goal locations and locations of obstacles would be randomized. Task Rules and Scoring The time-limit to complete this task is 8 minutes (480 secs) . For The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You will be explicitly scored on the distance traveled, hence, do you best to follow the shortest path possible to the goal. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Final distance to goal Euclidean distance from robot (measured from robot center) to the goal which is calculated at the time limit [8 minutes] ( Smaller is better ) 2 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 3 Completion time Time from launching the solution to task completion ( Smaller is better ) 4 Total travel distance Travel distance covered by the robot ( Smaller is better )","title":"Task 3: Go-to-goal navigation"},{"location":"phase1-instructions/task3/#task_3_go-to-goal_navigation","text":"The final task of this phase is to navigate safely through a park to reach the customer. The problem here is to navigate in an unconstrained but cluttered terrain without colliding with any obstacles. In this task you are required to move through a collision-free path to the goal using only your on-board sensors. Task 3 Goal: The goal of this task is to autonomously control the delivery robot from the robot start position to a goal location in the park without colliding with obstacles. To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details].","title":"Task 3: Go-to-goal navigation"},{"location":"phase1-instructions/task3/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks.","title":"Task Guidelines"},{"location":"phase1-instructions/task3/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the delivery robot in Gazebo and RViz: roslaunch parc-robot task3.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the orange-red sphere (the goal location ) in front of the person.","title":"1. Launching the Task"},{"location":"phase1-instructions/task3/#2_preparing_your_solution","text":"Your solution should be prepared as ROS packages to be saved in your solution folder [link to how to submit]. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task3_solution.launch . Hence, your solution to Task 3 should be run by calling the following commands simulatenously: In one terminal: roslaunch parc-robot task3.launch In another terminal: roslaunch your-package-name task3_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the goal locations and locations of obstacles would be randomized.","title":"2. Preparing your Solution"},{"location":"phase1-instructions/task3/#task_rules_and_scoring","text":"The time-limit to complete this task is 8 minutes (480 secs) . For The task is ONLY complete when ANY part of the robot is inside the orange-red sphere (goal location marker). You will be explicitly scored on the distance traveled, hence, do you best to follow the shortest path possible to the goal. Scoring for this task would be based on the following criteria: S/N Criteria / Metric Description 1 Final distance to goal Euclidean distance from robot (measured from robot center) to the goal which is calculated at the time limit [8 minutes] ( Smaller is better ) 2 Collisions Number of times the robot comes in contact with either obstacles, building, or walls ( Smaller is better ). 3 Completion time Time from launching the solution to task completion ( Smaller is better ) 4 Total travel distance Travel distance covered by the robot ( Smaller is better )","title":"Task Rules and Scoring"},{"location":"phase2-instructions/","text":"Phase 2: Physical Robot Welcome to Phase 2 of the PARC Engineers League Competition 2021. You are here because you qualified from the phase 1 of the competition. Congratulations! In this Phase, teams will improve and adapt their Phase 1 solutions for deployment on a physical robot to successfully complete the delivery task. Specifically, teams are required to develop and test their software iteratively in simulation and on the physical robot (remotely). The simulation platform remains Gazebo Simulator . Teams will improve their Phase 1 solutions in simulation and then test in real time on the physical robot through remote access. Delivery Robot Note The delivery robot used in Phase 2 is changed from what was used in Phase 1. However, we do not expect this to cause any issues with your software development. The delivery robot to be used in Phase 2 is the Turtlebot3 Burger . It is a ground mobile robotfitted with a 2D LiDAR (light detection and ranging or laser scanner) and an RGB camera. The figure below shows the delivey robot: physical robot (left) and simulated robot (right). Physical Field The physical field was built to emulate the realistic street structure with roads, sidewalks, a crosswalk, traffic signs and buildings explored in Phase 1. The entire field is 3.6 x 7.8 meters in dimension. A top view of the field is shown below: Simulation Environment The simulation environment is a modelled replica of the physical field with consistent features. Teams will use develop and test their software in this simulation environment before deploying on the physical robot and field. A top view of the simulation filed is shown below:","title":"Introduction"},{"location":"phase2-instructions/#phase_2_physical_robot","text":"Welcome to Phase 2 of the PARC Engineers League Competition 2021. You are here because you qualified from the phase 1 of the competition. Congratulations! In this Phase, teams will improve and adapt their Phase 1 solutions for deployment on a physical robot to successfully complete the delivery task. Specifically, teams are required to develop and test their software iteratively in simulation and on the physical robot (remotely). The simulation platform remains Gazebo Simulator . Teams will improve their Phase 1 solutions in simulation and then test in real time on the physical robot through remote access.","title":"Phase 2: Physical Robot"},{"location":"phase2-instructions/#delivery_robot","text":"Note The delivery robot used in Phase 2 is changed from what was used in Phase 1. However, we do not expect this to cause any issues with your software development. The delivery robot to be used in Phase 2 is the Turtlebot3 Burger . It is a ground mobile robotfitted with a 2D LiDAR (light detection and ranging or laser scanner) and an RGB camera. The figure below shows the delivey robot: physical robot (left) and simulated robot (right).","title":"Delivery Robot"},{"location":"phase2-instructions/#physical_field","text":"The physical field was built to emulate the realistic street structure with roads, sidewalks, a crosswalk, traffic signs and buildings explored in Phase 1. The entire field is 3.6 x 7.8 meters in dimension. A top view of the field is shown below:","title":"Physical Field"},{"location":"phase2-instructions/#simulation_environment","text":"The simulation environment is a modelled replica of the physical field with consistent features. Teams will use develop and test their software in this simulation environment before deploying on the physical robot and field. A top view of the simulation filed is shown below:","title":"Simulation Environment"},{"location":"phase2-instructions/getting-started-simulation/","text":"Getting Started In Simulation In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the Setting up your PC tutorial ). If you have already set up your PC and catkin_ws , skip to Install TurtleBot3 packages Setup ROS workspace (Only if you don't already have a catkin_ws) Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace Install TurtleBot3 packages via Debian packages sudo apt-get update sudo apt-get install ros-melodic-dynamixel-sdk sudo apt-get install ros-melodic-turtlebot3-msgs sudo apt-get install ros-melodic-turtlebot3 Clone the repository In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League-Phase2.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them. Install dependencies In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y Compile packages cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0 Set up ROS environment To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash Test installation If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch turtlebot3_parc turtlebot3_parc.launch Gazebo Simulator window RViz window Controlling the robot using keyboard Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch turtlebot3_parc teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Getting Started in Simulation"},{"location":"phase2-instructions/getting-started-simulation/#getting_started_in_simulation","text":"In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the Setting up your PC tutorial ). If you have already set up your PC and catkin_ws , skip to Install TurtleBot3 packages","title":"Getting Started In Simulation"},{"location":"phase2-instructions/getting-started-simulation/#setup_ros_workspace_only_if_you_dont_already_have_a_catkin_ws","text":"Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace","title":"Setup ROS workspace (Only if you don't already have a catkin_ws)"},{"location":"phase2-instructions/getting-started-simulation/#install_turtlebot3_packages_via_debian_packages","text":"sudo apt-get update sudo apt-get install ros-melodic-dynamixel-sdk sudo apt-get install ros-melodic-turtlebot3-msgs sudo apt-get install ros-melodic-turtlebot3","title":"Install TurtleBot3 packages via Debian packages"},{"location":"phase2-instructions/getting-started-simulation/#clone_the_repository","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/PARC-Engineers-League-Phase2.git Or if you already have cloned the repo without submodules, run command git submodule update --init --recursive to update them.","title":"Clone the repository"},{"location":"phase2-instructions/getting-started-simulation/#install_dependencies","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y","title":"Install dependencies"},{"location":"phase2-instructions/getting-started-simulation/#compile_packages","text":"cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash NOTE: There is a known issue while compiling, Intel RealSense SDK 2.0 is missing To solve, update the file realsense-ros/realsense_camera/CMakeLists.txt ,line: 43 to find_package(realsense2 2.36.0) i.e. downgrade the required version of realsense2 to 2.36.0","title":"Compile packages"},{"location":"phase2-instructions/getting-started-simulation/#set_up_ros_environment","text":"To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash","title":"Set up ROS environment"},{"location":"phase2-instructions/getting-started-simulation/#test_installation","text":"If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch turtlebot3_parc turtlebot3_parc.launch Gazebo Simulator window RViz window","title":"Test installation"},{"location":"phase2-instructions/getting-started-simulation/#controlling_the_robot_using_keyboard","text":"Run the following command in a new terminal source ~/catkin_ws/devel/setup.bash roslaunch turtlebot3_parc teleop.launch Now keeping the second terminal on top (teleop.launch) press i to move the robot forward, you can see the robot moving in \"RViz\" and \"Gazebo\" windows. you can use the keys shown below to move the robot and k key to stop the movement. Moving around: u i o j k l m , .","title":"Controlling the robot using keyboard"},{"location":"phase2-instructions/offline-development/","text":"Offline Development and Troubleshooting In the last section, we briefly introduced the use of rosbags for recording your test runs for later evaluation and troubleshooting. This is a very crucial step, hence, as a starter, we have prepared sample rosbags for you to explore. 1. Download the ROS bags Use this Google Drive link to download the ROS bags. NOTE: The files are large with a total size of ~370MB. Save the file on your computer and take note of the directory (it doesn't matter where you store it). For this tutorial, we will use rosbag-location . 2. Run the ROS bags First, open a new terminal and start up roscore : roscore In another terminal, open up rviz rosrun rviz rviz -d $(rospack find turtlebot3_parc)/rviz/turtlebot3_parc.rviz Finally, in another terminal, run the rosbag play command and pass the ros bag you want to play: # navigate to the rosbag-location directory and then run the command: rosbag play task-part1.bag We strongly recommend that you play around with the three rosbags and observe the data carefully to explore best ways to complete the task. 3. Create your own ROS bags The last task is for you to create rosbags of your own from your team test sessions. For this, start by checking out the link for the official documentation on rosbags. As state in the previous section, give it a try follow the instructions below: # in a new terminal on the host PC, run: rosbag record -a # this is to record all the topics. This might lead to a very large *.bag file # check out other rosbag commands such as play , compress , etc. Follow this link for a video tutorial.","title":"Offline Development and Troubleshooting"},{"location":"phase2-instructions/offline-development/#offline_development_and_troubleshooting","text":"In the last section, we briefly introduced the use of rosbags for recording your test runs for later evaluation and troubleshooting. This is a very crucial step, hence, as a starter, we have prepared sample rosbags for you to explore.","title":"Offline Development and Troubleshooting"},{"location":"phase2-instructions/offline-development/#1_download_the_ros_bags","text":"Use this Google Drive link to download the ROS bags. NOTE: The files are large with a total size of ~370MB. Save the file on your computer and take note of the directory (it doesn't matter where you store it). For this tutorial, we will use rosbag-location .","title":"1. Download the ROS bags"},{"location":"phase2-instructions/offline-development/#2_run_the_ros_bags","text":"First, open a new terminal and start up roscore : roscore In another terminal, open up rviz rosrun rviz rviz -d $(rospack find turtlebot3_parc)/rviz/turtlebot3_parc.rviz Finally, in another terminal, run the rosbag play command and pass the ros bag you want to play: # navigate to the rosbag-location directory and then run the command: rosbag play task-part1.bag We strongly recommend that you play around with the three rosbags and observe the data carefully to explore best ways to complete the task.","title":"2. Run the ROS bags"},{"location":"phase2-instructions/offline-development/#3_create_your_own_ros_bags","text":"The last task is for you to create rosbags of your own from your team test sessions. For this, start by checking out the link for the official documentation on rosbags. As state in the previous section, give it a try follow the instructions below: # in a new terminal on the host PC, run: rosbag record -a # this is to record all the topics. This might lead to a very large *.bag file # check out other rosbag commands such as play , compress , etc. Follow this link for a video tutorial.","title":"3. Create your own ROS bags"},{"location":"phase2-instructions/physical-robot-mode/","text":"Testing on Physical Robot Teams will be able to test their software on the physical robot once every week for a testing window of two (2) hours. Schedule your Test Time To schedule your test time every week, please visit the Test Scheduler . Click \"Slot me in\" and the insert your team name and email address. You will receive an email containing your login details no later than 1 hour before your session is to begin. If you can't find a convenient time on the schedule, we have a back up time every week (3-5pm GMT). Reach out to us here to schedule that. Accessing the Physical Robot During your scheduled session, you will be provided remote access to control the robot using the following protocol: Remote Desktop Connection: Using remote desktop software (e.g. TeamViewer), you will be able to remotely view and control the Host PC in our base location in Senegal. SSH (Secure Shell Protocol): This protocol enable commandline access and remote command execution on the robot PC (Raspberry Pi). Step 0: Prerequisites Install TeamViewer remote deskstop software on your PC. For download instructions, see here Step 1: Access the Host PC using TeamViewer You will receive an email for our technical team on the day of your scheduled session with the following information: User ID and Password for accessing the TeamViewer account on the Host PC Password of the Host PC Step 2: Open a terminal on the Host PC We recommend you use the Terminator terminal as it enables you split the terminal screen efficiently. Step 3: Create your own team workspace Please check the Team Naming Convention page to find your official team numbered name. # change directory to team_workspaces cd ~/team_workspaces # create your team workspace folder, i.e. official-team-numbered-name , e.g. team-1-asimov mkdir -p official-team-numbered-name /src # change directory into the new folder and run the workspace command cd official-team-numbered-name catkin_init_workspace src # make your entire workspace catkin_make Step 4: Clone your github repository into your \"src\" folder cd ~/team_workspaces/ official-team-numbered-name /src git clone your-git-repository Step 5: Ensure all your dependencies are installed cd ~/team_workspaces/ official-team-numbered-name / sudo apt update rosdep install --from-paths ./src --ignore-src -y # Also, you might need to manually install any other packages required Step 6: Compile your solution cd ~/team_workspaces/ official-team-numbered-name catkin_make Step 7: Find the current IP of the Robot PC (ubuntu) # open a new terminal sudo nmap -sn 192.168.1.0/24 # you will be prompted to provide a password, type: daust # note the IP address of the device with hostname: ubuntu Step 8: Create a bash session on the robot using the SSH protocol # open a new terminal ssh ubuntu@ IP-address-from-step-7 # e.g. ssh ubuntu@192.168.1.112 # you will be prompted to provide a password, type: turtlebot Step 9: Bring up the robot # on the host PC, i.e. terminal with daust@daust , run: roscore # on the open robot bash session, i.e. ubuntu@ubuntu:~$ , run roslaunch turtlebot3_parc turtlebot3_robot.launch # check that the robot is publishing topics on the ROS network # on your host PC: roslaunch parc-robot robot.launch # this will launch RViz and show the robot If everything is working properly, you should have the RViz window looking like the image below: Step 10: Run your solution # on the host PC: source ~/team_workspaces/ official-team-numbered-name /devel/setup.bash roslaunch your-package-name task_solution.launch Saving your tests for offline troubleshooting It is important that you save your data during your testing period to enable you run troubleshooting offline on your own time. ROS provides a very convenient tool, called rosbags , to enable you record the data generated during your runs and play them back later. Please check out the link for the official documentation on rosbags. To give it a try, follow the instructions below: # in a new terminal on the host PC, run: rosbag record -a # this is to record all the topics. This might lead to a very large *.bag file # check out other rosbag commands such as play , compress , etc. Follow this link for a video tutorial.","title":"Testing on Physical Robot"},{"location":"phase2-instructions/physical-robot-mode/#testing_on_physical_robot","text":"Teams will be able to test their software on the physical robot once every week for a testing window of two (2) hours.","title":"Testing on Physical Robot"},{"location":"phase2-instructions/physical-robot-mode/#schedule_your_test_time","text":"To schedule your test time every week, please visit the Test Scheduler . Click \"Slot me in\" and the insert your team name and email address. You will receive an email containing your login details no later than 1 hour before your session is to begin. If you can't find a convenient time on the schedule, we have a back up time every week (3-5pm GMT). Reach out to us here to schedule that.","title":"Schedule your Test Time"},{"location":"phase2-instructions/physical-robot-mode/#accessing_the_physical_robot","text":"During your scheduled session, you will be provided remote access to control the robot using the following protocol: Remote Desktop Connection: Using remote desktop software (e.g. TeamViewer), you will be able to remotely view and control the Host PC in our base location in Senegal. SSH (Secure Shell Protocol): This protocol enable commandline access and remote command execution on the robot PC (Raspberry Pi).","title":"Accessing the Physical Robot"},{"location":"phase2-instructions/physical-robot-mode/#step_0_prerequisites","text":"Install TeamViewer remote deskstop software on your PC. For download instructions, see here","title":"Step 0: Prerequisites"},{"location":"phase2-instructions/physical-robot-mode/#step_1_access_the_host_pc_using_teamviewer","text":"You will receive an email for our technical team on the day of your scheduled session with the following information: User ID and Password for accessing the TeamViewer account on the Host PC Password of the Host PC","title":"Step 1: Access the Host PC using TeamViewer"},{"location":"phase2-instructions/physical-robot-mode/#step_2_open_a_terminal_on_the_host_pc","text":"We recommend you use the Terminator terminal as it enables you split the terminal screen efficiently.","title":"Step 2: Open a terminal on the Host PC"},{"location":"phase2-instructions/physical-robot-mode/#step_3_create_your_own_team_workspace","text":"Please check the Team Naming Convention page to find your official team numbered name. # change directory to team_workspaces cd ~/team_workspaces # create your team workspace folder, i.e. official-team-numbered-name , e.g. team-1-asimov mkdir -p official-team-numbered-name /src # change directory into the new folder and run the workspace command cd official-team-numbered-name catkin_init_workspace src # make your entire workspace catkin_make","title":"Step 3: Create your own team workspace"},{"location":"phase2-instructions/physical-robot-mode/#step_4_clone_your_github_repository_into_your_src_folder","text":"cd ~/team_workspaces/ official-team-numbered-name /src git clone your-git-repository","title":"Step 4: Clone your github repository into your \"src\" folder"},{"location":"phase2-instructions/physical-robot-mode/#step_5_ensure_all_your_dependencies_are_installed","text":"cd ~/team_workspaces/ official-team-numbered-name / sudo apt update rosdep install --from-paths ./src --ignore-src -y # Also, you might need to manually install any other packages required","title":"Step 5: Ensure all your dependencies are installed"},{"location":"phase2-instructions/physical-robot-mode/#step_6_compile_your_solution","text":"cd ~/team_workspaces/ official-team-numbered-name catkin_make","title":"Step 6: Compile your solution"},{"location":"phase2-instructions/physical-robot-mode/#step_7_find_the_current_ip_of_the_robot_pc_ubuntu","text":"# open a new terminal sudo nmap -sn 192.168.1.0/24 # you will be prompted to provide a password, type: daust # note the IP address of the device with hostname: ubuntu","title":"Step 7: Find the current IP of the Robot PC (ubuntu)"},{"location":"phase2-instructions/physical-robot-mode/#step_8_create_a_bash_session_on_the_robot_using_the_ssh_protocol","text":"# open a new terminal ssh ubuntu@ IP-address-from-step-7 # e.g. ssh ubuntu@192.168.1.112 # you will be prompted to provide a password, type: turtlebot","title":"Step 8: Create a bash session on the robot using the SSH protocol"},{"location":"phase2-instructions/physical-robot-mode/#step_9_bring_up_the_robot","text":"# on the host PC, i.e. terminal with daust@daust , run: roscore # on the open robot bash session, i.e. ubuntu@ubuntu:~$ , run roslaunch turtlebot3_parc turtlebot3_robot.launch # check that the robot is publishing topics on the ROS network # on your host PC: roslaunch parc-robot robot.launch # this will launch RViz and show the robot If everything is working properly, you should have the RViz window looking like the image below:","title":"Step 9: Bring up the robot"},{"location":"phase2-instructions/physical-robot-mode/#step_10_run_your_solution","text":"# on the host PC: source ~/team_workspaces/ official-team-numbered-name /devel/setup.bash roslaunch your-package-name task_solution.launch","title":"Step 10: Run your solution"},{"location":"phase2-instructions/physical-robot-mode/#saving_your_tests_for_offline_troubleshooting","text":"It is important that you save your data during your testing period to enable you run troubleshooting offline on your own time. ROS provides a very convenient tool, called rosbags , to enable you record the data generated during your runs and play them back later. Please check out the link for the official documentation on rosbags. To give it a try, follow the instructions below: # in a new terminal on the host PC, run: rosbag record -a # this is to record all the topics. This might lead to a very large *.bag file # check out other rosbag commands such as play , compress , etc. Follow this link for a video tutorial.","title":"Saving your tests for offline troubleshooting"},{"location":"phase2-instructions/simulation-mode/","text":"Developing in Simulation The goal here is to solve the complete delivery robot navigation task which is a combination of the three tasks completed in Phase 1, namely: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) In this Phase 2, you are required to do the following: Refine your solution to the different tasks to make sure they function as expected Combine your solutions together into one complete solution that manages the different tasks together in real-time (as shown in image above) Task Guidelines Note Make sure you have completed the Getting Started in Simulation before starting the task. 1. Launching the Task In a new terminal, run the following launch file to bring up the robot in Gazebo and RViz: roslaunch turtlebot_parc turtlebot_parc.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the circular green marker on the wall which represents the final goal location . The arrow in the figure below shows the robot in the goal location, facing the circular green marker. The goal is to get as close to the green marker and then stop. The robot camera view is also show below. 2. Explore Multiple Routes We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch turtlebot_parc turtlebot_parc.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations. 3. Explore Multiple Start Delays We have provided a simple way to set arbitrary values for the traffic light durations such as red_green_duration , yellow_red_duration and green_yellow_duration . This can be done by passing an argument for any or all of them as follows: roslaunch turtlebot_parc turtlebot_parc.launch red_green_duration:=10 green_yellow_duration:=8 While developing, we recommend you play around with different values for the traffic light durations to ensure your solution is robust. 3. Preparing your Solution Consistent with the approach from Phase 1, your solution should be prepared as ROS packages to be saved in your solution folder. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task_solution.launch . Hence, your solution should be run by calling the following commands simulatenously: In one terminal: roslaunch turtlebot_parc turtlebot_parc.launch In another terminal: roslaunch your-package-name task_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles would be randomized in the field.","title":"Developing in Simulation"},{"location":"phase2-instructions/simulation-mode/#developing_in_simulation","text":"The goal here is to solve the complete delivery robot navigation task which is a combination of the three tasks completed in Phase 1, namely: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) In this Phase 2, you are required to do the following: Refine your solution to the different tasks to make sure they function as expected Combine your solutions together into one complete solution that manages the different tasks together in real-time (as shown in image above)","title":"Developing in Simulation"},{"location":"phase2-instructions/simulation-mode/#task_guidelines","text":"Note Make sure you have completed the Getting Started in Simulation before starting the task.","title":"Task Guidelines"},{"location":"phase2-instructions/simulation-mode/#1_launching_the_task","text":"In a new terminal, run the following launch file to bring up the robot in Gazebo and RViz: roslaunch turtlebot_parc turtlebot_parc.launch You should see the display below in Gazebo. To the right, there's the robot and to the left is the circular green marker on the wall which represents the final goal location . The arrow in the figure below shows the robot in the goal location, facing the circular green marker. The goal is to get as close to the green marker and then stop. The robot camera view is also show below.","title":"1. Launching the Task"},{"location":"phase2-instructions/simulation-mode/#2_explore_multiple_routes","text":"We have prepared two pre-defined routes you can use as you develop your solution. The default route is route1 , but you can select the second route option ( route2 ) by passing the argument in the roslaunch command as follows: roslaunch turtlebot_parc turtlebot_parc.launch route:=route2 We recommend you play around with at least these two routes to ensure your solution is robust to different start locations.","title":"2. Explore Multiple Routes"},{"location":"phase2-instructions/simulation-mode/#3_explore_multiple_start_delays","text":"We have provided a simple way to set arbitrary values for the traffic light durations such as red_green_duration , yellow_red_duration and green_yellow_duration . This can be done by passing an argument for any or all of them as follows: roslaunch turtlebot_parc turtlebot_parc.launch red_green_duration:=10 green_yellow_duration:=8 While developing, we recommend you play around with different values for the traffic light durations to ensure your solution is robust.","title":"3. Explore Multiple Start Delays"},{"location":"phase2-instructions/simulation-mode/#3_preparing_your_solution","text":"Consistent with the approach from Phase 1, your solution should be prepared as ROS packages to be saved in your solution folder. Create a launch file in your ROS package which runs ALL the code you need in your solution. Name this launch file: task_solution.launch . Hence, your solution should be run by calling the following commands simulatenously: In one terminal: roslaunch turtlebot_parc turtlebot_parc.launch In another terminal: roslaunch your-package-name task_solution.launch Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position and locations of obstacles would be randomized in the field.","title":"3. Preparing your Solution"},{"location":"phase2-instructions/submission-info/","text":"What to Submit There are four (4) items to submit as we finalize the competition: Item Deadline Project Report August 25th 2021 Project Presentation Video August 26th 2021 Software Package(s) - For Physical Robot August 26th 2021 Software Package(s) - For Simulation August 27th 2021 Please see detailed instructions on how to submit below. Project Report Due Date: 11:59PM on August 25th, 2021 (Eastern African Time) This is your final report summarizing the work done and lessons learned by your team in the competition. Please pay attention to the format and requirements below: Format: Title Page (include team name, country name) Table of Contents Introduction Methodology: System Software Framework + Description Results Challenges and Lessons Learned Conclusion Report requirements: Length: 7-10 pages (max 10 pages) excluding title page and table of contents page Language: English and French Paper format: PDF, A4 size Formatting: Font size should be 12, 1.5 line spacing, margins of at least 1 inch Be sure to include figures, sketches, diagrams to illustrate your work Submit your Project Report here . Project Presentation Video Due Date: 11:59PM on August 26th, 2021 (Eastern African Time) Format: Prepare slide presentation consistent with your project report. In the presentation, the teams should summarize their work done and lessons learned. The presentation will be played on the final competition day and be evaluated by the judges. The following sections must be in your slides: Introduction (Make sure to list all the team members) Methodology: System Software Framework + Description Results Challenges and Lessons Learned Report requirements: Length: max 5 minutes Language: English and French Format: MP4 Participation: Display an image of all the team members in your recorded video Submit your Project Presentation Video here . Software Package(s) - For Physical Robot Due Date: 11:59PM on August 26th, 2021 (Eastern African Time) The final item to submit is a zipped folder of your entire software solution. Please carefully review and follow the How to Submit page for the format of your submission. In this case, you have ONLY ONE TASK, hence, kindly adjust your README.md file to show only one task and provide the commands to run to launch your solution. Submit your Software Package (For Physical Robot) here . Software Package(s) - For Simulation Due Date: 11:59PM on August 27th, 2021 (Eastern African Time) Please follow the same format as above (for the Physical Robot case). Please carefully review and follow the How to Submit page for the format of your submission. In this case, you have ONLY ONE TASK, hence, kindly adjust your README.md file to show only one task and provide the commands to run to launch your solution. Submit your Software Package (For Simulation) here . Rubric for Submissions As you prepare your submissions, please ensure you review the rubric here to make sure you adhere to the guidelines and earn full points.","title":"What to Submit"},{"location":"phase2-instructions/submission-info/#what_to_submit","text":"There are four (4) items to submit as we finalize the competition: Item Deadline Project Report August 25th 2021 Project Presentation Video August 26th 2021 Software Package(s) - For Physical Robot August 26th 2021 Software Package(s) - For Simulation August 27th 2021 Please see detailed instructions on how to submit below.","title":"What to Submit"},{"location":"phase2-instructions/submission-info/#project_report","text":"","title":"Project Report"},{"location":"phase2-instructions/submission-info/#due_date_1159pm_on_august_25th_2021_eastern_african_time","text":"This is your final report summarizing the work done and lessons learned by your team in the competition. Please pay attention to the format and requirements below: Format: Title Page (include team name, country name) Table of Contents Introduction Methodology: System Software Framework + Description Results Challenges and Lessons Learned Conclusion Report requirements: Length: 7-10 pages (max 10 pages) excluding title page and table of contents page Language: English and French Paper format: PDF, A4 size Formatting: Font size should be 12, 1.5 line spacing, margins of at least 1 inch Be sure to include figures, sketches, diagrams to illustrate your work Submit your Project Report here .","title":"Due Date: 11:59PM on August 25th, 2021 (Eastern African Time)"},{"location":"phase2-instructions/submission-info/#project_presentation_video","text":"","title":"Project Presentation Video"},{"location":"phase2-instructions/submission-info/#due_date_1159pm_on_august_26th_2021_eastern_african_time","text":"Format: Prepare slide presentation consistent with your project report. In the presentation, the teams should summarize their work done and lessons learned. The presentation will be played on the final competition day and be evaluated by the judges. The following sections must be in your slides: Introduction (Make sure to list all the team members) Methodology: System Software Framework + Description Results Challenges and Lessons Learned Report requirements: Length: max 5 minutes Language: English and French Format: MP4 Participation: Display an image of all the team members in your recorded video Submit your Project Presentation Video here .","title":"Due Date: 11:59PM on August 26th, 2021 (Eastern African Time)"},{"location":"phase2-instructions/submission-info/#software_packages_-_for_physical_robot","text":"","title":"Software Package(s) - For Physical Robot"},{"location":"phase2-instructions/submission-info/#due_date_1159pm_on_august_26th_2021_eastern_african_time_1","text":"The final item to submit is a zipped folder of your entire software solution. Please carefully review and follow the How to Submit page for the format of your submission. In this case, you have ONLY ONE TASK, hence, kindly adjust your README.md file to show only one task and provide the commands to run to launch your solution. Submit your Software Package (For Physical Robot) here .","title":"Due Date: 11:59PM on August 26th, 2021 (Eastern African Time)"},{"location":"phase2-instructions/submission-info/#software_packages_-_for_simulation","text":"","title":"Software Package(s) - For Simulation"},{"location":"phase2-instructions/submission-info/#due_date_1159pm_on_august_27th_2021_eastern_african_time","text":"Please follow the same format as above (for the Physical Robot case). Please carefully review and follow the How to Submit page for the format of your submission. In this case, you have ONLY ONE TASK, hence, kindly adjust your README.md file to show only one task and provide the commands to run to launch your solution. Submit your Software Package (For Simulation) here .","title":"Due Date: 11:59PM on August 27th, 2021 (Eastern African Time)"},{"location":"phase2-instructions/submission-info/#rubric_for_submissions","text":"As you prepare your submissions, please ensure you review the rubric here to make sure you adhere to the guidelines and earn full points.","title":"Rubric for Submissions"},{"location":"phase2-instructions/team-names/","text":"Team Naming Convention To ensure consistency, we have provided a naming convention for all the qualified teams. Please find your official team numbered name below. You will use this in naming your team folder on the host PC. Official Team Numbered Name Team Name team-1-asimov Team Asimov team-2-ethiopia Team Ethiopia team-3-kognitive Kognitive Robotics team-4-robotsmali Team RobotsMali team-5-seebar Seebar Enterprise team-6-smarafeduk Smaraf Eduk team-7-ugrobotics UG Robotics","title":"Team Naming Convention"},{"location":"phase2-instructions/team-names/#team_naming_convention","text":"To ensure consistency, we have provided a naming convention for all the qualified teams. Please find your official team numbered name below. You will use this in naming your team folder on the host PC. Official Team Numbered Name Team Name team-1-asimov Team Asimov team-2-ethiopia Team Ethiopia team-3-kognitive Kognitive Robotics team-4-robotsmali Team RobotsMali team-5-seebar Seebar Enterprise team-6-smarafeduk Smaraf Eduk team-7-ugrobotics UG Robotics","title":"Team Naming Convention"}]}